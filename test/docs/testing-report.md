# Test Evaluation Report
## AI-Powered Jira Agent

**Evaluation Timestamp**: 2025-10-25 22:25:16
**Total Test Runs**: 1

## Metrics Summary

| Metric | Value | Target | Status |
|--------|-------|--------|--------|
| Structural Validity | 0/1 (0.0%) | ‚â•95% | ‚ùå |
| Completeness | 0/1 (0.0%) | 100% | ‚ùå |
| Risk Coverage | 1/1 (100.0%) | 100% | ‚úÖ |
| Export Success | 1/1 (100.0%) | 100% | ‚úÖ |
| Consistency Score | 87.5/100 | ‚â•90 | ‚ùå |
| Avg E2E Time | 6.24s | Monitor | üìä |

## Detailed Results

### Structural Validity
- **Passed**: 0 out of 1 runs
- **Rate**: 0.0%
- **Status**: FAIL

### Completeness (Constraints)
- **Stories per epic**: 3-5
- **Test cases per story**: 2-3  
- **Passed**: 0 out of 1 runs
- **Rate**: 0.0%
- **Status**: FAIL

### Risk Coverage
- **High-risk stories**: ‚â•3 test cases with negative + resilience
- **Passed**: 1 out of 1 runs
- **Rate**: 100.0%
- **Status**: PASS

### Export Functionality
- **JSON Export**: /runs/{id}/json
- **CSV Export**: /runs/{id}/csv
- **Passed**: 1 out of 1 runs
- **Rate**: 100.0%
- **Status**: PASS

### Performance
- **Average execution time**: 6.24 seconds
- **Individual times**: 6.24s

## Recommendations

‚ö†Ô∏è **SOME TARGETS NOT MET** - Review the following areas:

- Schema validation needs improvement
- Story/test case constraints not consistently met  


- Output consistency needs improvement

## Next Steps

1. Review detailed test logs for failing cases
2. Check defect log for open issues
3. Address critical issues before release
4. Re-run evaluation after fixes

---
*Report generated by Test Evaluation Runner*
